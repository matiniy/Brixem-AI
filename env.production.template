# Brixem AI - Production Environment Variables
# Copy this file to .env.local for local development
# Add these same variables to your Vercel dashboard for production

# ===========================================
# GROQ AI CONFIGURATION (Primary AI Provider)
# ===========================================
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-70b-versatile
GROQ_MAX_TOKENS=1000
GROQ_TEMPERATURE=0.7

# ===========================================
# SUPABASE CONFIGURATION
# ===========================================
NEXT_PUBLIC_SUPABASE_URL=https://npclviylnwigldpfvscw.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key_here

# ===========================================
# FEATURE FLAGS
# ===========================================
NEXT_PUBLIC_CHAT_FIRST=1

# ===========================================
# OPTIONAL: OLLAMA CONFIGURATION (Fallback AI)
# ===========================================
# OLLAMA_BASE_URL=http://localhost:11434

# ===========================================
# OPTIONAL: OPENAI CONFIGURATION (Backup/Alternative)
# ===========================================
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_MAX_TOKENS=1000
# OPENAI_TEMPERATURE=0.7

# ===========================================
# DEPLOYMENT NOTES
# ===========================================
# 1. For local development: Copy this file to .env.local
# 2. For Vercel production: Add these variables in Vercel dashboard
# 3. Make sure to get the correct SUPABASE_SERVICE_ROLE_KEY from Supabase dashboard
# 4. The GROQ_API_KEY is already provided and working
